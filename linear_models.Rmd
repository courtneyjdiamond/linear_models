---
title: "Linear Models"
author: "Courtney Diamond"
date: "2023-11-27"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load key packages

```{r}
library(tidyverse)
library(p8105.datasets)
```

## Load and clean the airbnb data
```{r}
data("nyc_airbnb")

nyc_airbnb = 
  nyc_airbnb |> 
  mutate(stars = review_scores_location /2) |> 
  select(price, stars, borough = neighbourhood_group, neighbourhood, room_type) |> 
  filter(borough != "Staten Island")

view(nyc_airbnb)
```

Let's fit a model

```{r}
fit = 
  nyc_airbnb |> 
  lm(price ~ stars + borough, data = _)
```

Let's look at our model. 

```{r}
summary(fit)$coef
coef(fit)
## fitted.values(fit)
```

Tidy up the output instead. 

```{r}
fit |> 
  broom::glance()
```

Tidy up the coefficients
```{r}
fit |> 
  broom::tidy() |> 
  mutate(term = str_replace(term, "^borough", "Borough: ")) |> 
  select(term, estimate, p.value) |> 
  knitr::kable(digits = 3)
```


Let's try something else. This changes the reference group by refactoring. 

```{r}
fit2 = 
  nyc_airbnb |> 
  mutate(
    borough = fct_infreq(borough),
    room_type = fct_infreq(room_type)
  ) |> 
  lm(price ~ stars + borough + room_type, data = _)

fit2 |> 
  broom::tidy()
```


## Quick look at diagnostics

```{r}
nyc_airbnb |> 
  modelr::add_residuals(fit2) |> 
  ggplot(aes(x = resid)) +
  geom_density() +
  xlim(-100, 500)

nyc_airbnb |> 
  modelr::add_residuals(fit2) |> 
  ggplot(aes(x = borough, y = resid)) +
  geom_violin()

nyc_airbnb |> 
  modelr::add_residuals(fit2) |> 
  ggplot(aes(x = stars, y = resid)) +
  geom_point()
```


Let's try with a qqplot

```{r}
nyc_airbnb |> 
  modelr::add_residuals(fit2) |> 
  ggplot(aes(sample = resid)) +
  stat_qq() +
  stat_qq_line()
```

## Hypothesis test for categorical predictor

Fit a "null" and alternative model

```{r}
fit_null = lm(price ~ stars + borough, data = nyc_airbnb)
fit_alt = lm(price ~ stars + borough + room_type, data = nyc_airbnb)

anova(fit_null, fit_alt) |> 
  broom::tidy()
```

## Borough-level differences

Use interaction effects

```{r}
fit3 = nyc_airbnb |> 
  lm(price ~ stars * borough + room_type * borough, data = _)

fit3 |> 
  broom::tidy()
```

Alternative: create separate models for each borough

```{r}
airbnb_lm = function(df) {
  fit = 
    lm(price ~ stars + room_type, data = df)
}

nyc_airbnb |> 
  nest(df = -borough) |> 
  mutate(
    models = map(df, airbnb_lm), 
    results = map(models, broom::tidy)
  ) |> 
  select(borough, results) |> 
  unnest(results) |> 
  select(borough, term, estimate) |> 
  pivot_wider(
    names_from = term, 
    values_from = estimate
  ) |> 
  knitr::kable(digits = 2)
```

Same thing, but slightly differently using an anon function

```{r}

nyc_airbnb |> 
  nest(df = -borough) |> 
  mutate(
    models = map(df, \(df) lm(price ~ stars + room_type, data = df)), 
    results = map(models, broom::tidy)
  ) |> 
  select(borough, results) |> 
  unnest(results) |> 
  select(borough, term, estimate) |> 
  pivot_wider(
    names_from = term, 
    values_from = estimate
  ) |> 
  knitr::kable(digits = 2)
```

## Binary outcomes

Homicides in Baltimore

```{r}
baltimore_df = 
  read_csv("data/homicide-data.csv") |> 
  filter(city == "Baltimore") |> 
  mutate(
    resolved = as.numeric(disposition == "Closed by arrest"),
    victim_age = as.numeric(victim_age)
  ) |> 
  select(resolved, victim_age, victim_race, victim_sex)

view(baltimore_df)
```

fitting a logistic regression

```{r}
fit_logistic = 
  baltimore_df |> 
  glm(resolved ~ victim_age + victim_race + victim_sex,
      data = _,
      family = binomial())
```

Look at model results

```{r}
fit_logistic |> 
  broom::tidy() |> 
  mutate(OR = exp(estimate)) |> 
  select(term, estimate, OR)
```

